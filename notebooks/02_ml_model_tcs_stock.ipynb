{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cbc4a07",
   "metadata": {},
   "source": [
    "# TCS Stock Data — Machine Learning Models\n",
    "**Internship Project | TCS Stock Data – Live and Latest**\n",
    "\n",
    "This notebook trains and evaluates machine learning models to predict the TCS closing price.\n",
    "\n",
    "### Models covered:\n",
    "| # | Model | Type | Library |\n",
    "|---|---|---|---|\n",
    "| A | Linear Regression | Baseline | scikit-learn |\n",
    "| B | Random Forest | Ensemble | scikit-learn |\n",
    "| C | LSTM | Deep Learning | TensorFlow/Keras |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4347bd4b",
   "metadata": {},
   "source": [
    "## 0. Setup — Imports and Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a11cf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to sys.path\n",
    "PROJECT_ROOT = os.path.dirname(os.getcwd())\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model    import LinearRegression\n",
    "from sklearn.ensemble        import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import MinMaxScaler\n",
    "from sklearn.metrics         import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Project modules\n",
    "from src.data_loader import load_tcs_data\n",
    "from src.features    import build_features\n",
    "from src.models      import (\n",
    "    prepare_ml_data,\n",
    "    run_linear_regression,\n",
    "    run_random_forest,\n",
    "    run_lstm,\n",
    ")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print('✓ Imports complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80077662",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3a4898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "raw_df = load_tcs_data()\n",
    "print(f'Raw data shape  : {raw_df.shape}')\n",
    "raw_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ec6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build feature-enriched DataFrame (adds lags, MAs, calendar features, etc.)\n",
    "feature_df = build_features(raw_df)\n",
    "print(f'\\nFeature DataFrame shape: {feature_df.shape}')\n",
    "feature_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All feature columns available for modeling\n",
    "print('Features in the enriched DataFrame:')\n",
    "for i, col in enumerate(feature_df.columns, 1):\n",
    "    print(f'  {i:2}. {col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2921c334",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Model A — Linear Regression (Baseline)\n",
    "\n",
    "**Why start here?**  \n",
    "Linear Regression is interpretable and fast. It serves as a *baseline* — if our complex models can't beat this, something is wrong.\n",
    "\n",
    "**How it works:**  \n",
    "It fits a straight-line (hyperplane) relationship: `Close ≈ w₁·Open + w₂·Prev_Close_1 + ... + b`\n",
    "\n",
    "**Metrics explained:**\n",
    "- **MSE (Mean Squared Error)** — average squared error (lower = better)\n",
    "- **RMSE** — same unit as price, easier to interpret (lower = better)\n",
    "- **MAE** — average absolute error in INR (lower = better)\n",
    "- **R²** — proportion of variance explained, 1.0 = perfect, 0 = no better than mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd61859",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = run_linear_regression(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba673c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the model coefficients (what the model learned)\n",
    "from src.models import LR_FEATURES\n",
    "available_features = [f for f in LR_FEATURES if f in feature_df.columns]\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature'    : available_features,\n",
    "    'Coefficient': lr_model.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print('Linear Regression Coefficients (sorted by |magnitude|):')\n",
    "print(coef_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4553a53c",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Model B — Random Forest Regressor\n",
    "\n",
    "**Why Random Forest?**  \n",
    "Stock prices have many non-linear interactions. Decision trees can model these, and\n",
    "Random Forest reduces overfitting by averaging over many trees (bagging ensemble).\n",
    "\n",
    "**n_estimators = 100** means we build 100 decision trees and average their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e044700",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = run_random_forest(feature_df, n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdeb6ce",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Model Comparison — LR vs Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-compute metrics for comparison table\n",
    "from src.models import LR_FEATURES, TARGET\n",
    "\n",
    "X_train, X_test, y_train, y_test, dates_test, _ = prepare_ml_data(feature_df)\n",
    "\n",
    "results = {}\n",
    "for name, model in [('Linear Regression', lr_model), ('Random Forest', rf_model)]:\n",
    "    y_pred = model.predict(X_test)\n",
    "    results[name] = {\n",
    "        'MAE'  : mean_absolute_error(y_test, y_pred),\n",
    "        'RMSE' : np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'R²'   : r2_score(y_test, y_pred),\n",
    "    }\n",
    "\n",
    "comparison_df = pd.DataFrame(results).T.round(4)\n",
    "print('Model Performance Comparison:')\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a903b3fb",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Model C — LSTM (Optional Deep Learning)\n",
    "\n",
    "**What is LSTM?**  \n",
    "Long Short-Term Memory is a special type of Recurrent Neural Network (RNN) designed to learn long-range dependencies in sequences. Unlike Linear Regression, it processes price sequences (e.g. the last 60 trading days) to predict the next day's price.\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Input (60 days) → LSTM(64) → Dropout(0.2) → LSTM(32) → Dropout(0.2) → Dense(1) → Predicted Close\n",
    "```\n",
    "\n",
    "> ⚠️ **Requires TensorFlow.** If not installed, run: `pip install tensorflow`  \n",
    "> Training may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ef7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LSTM model on the raw Close price series (uses raw_df, not feature_df)\n",
    "lstm_result = run_lstm(raw_df, lookback=60, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c66723b",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Conclusions and Observations\n",
    "\n",
    "| Model | Strengths | Weaknesses |\n",
    "|---|---|---|\n",
    "| Linear Regression | Fast, interpretable | Assumes linearity, misses complex patterns |\n",
    "| Random Forest | Handles non-linearity, robust | Black-box, can overfit without tuning |\n",
    "| LSTM | Understands sequences over time | Requires more data, slower training, complex to tune |\n",
    "\n",
    "### Key Takeaways:\n",
    "- `Prev_Close_1` (yesterday's price) is consistently the #1 most important feature.\n",
    "- Moving average features (MA_7, MA_30) help capture trend direction.\n",
    "- Random Forest typically outperforms Linear Regression on financial data.\n",
    "- LSTM adds value for truly sequential modelling but requires careful tuning.\n",
    "\n",
    "### Future Improvements:\n",
    "- Try **XGBoost** or **LightGBM** for even better tree-based performance.\n",
    "- Use **ARIMA / SARIMA** for classical time-series forecasting.\n",
    "- Add **external sentiment data** (news headlines) as features.\n",
    "- Implement **hyperparameter tuning** with `GridSearchCV` or `Optuna`.\n",
    "- Deploy as a **Flask/Streamlit web app** for real-time predictions."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
