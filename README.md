# TCS Stock Data – Live and Latest

> **Internship Project | Data Analyst Role**  
> End-to-end analysis and machine learning prediction of TCS (Tata Consultancy Services) stock prices.

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue?logo=python)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Complete-brightgreen)]()
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ManishPatil2005/tcs-stock-data-live-latest/blob/main/notebooks/03_tcs_stock_one_click_colab.ipynb)

---

## Project Overview

This project analyses the historical stock price data of **TCS (NSE: TCS)**, one of India's largest IT companies, and builds machine learning models to predict its future closing prices.

**What this project does:**
- Loads and cleans historical TCS stock data from a CSV file
- Auto-fetches latest TCS stock data from Yahoo Finance when local data is missing
- Performs detailed **Exploratory Data Analysis (EDA)** with visualisations
- Engineers time-based and lag features for ML modeling
- Trains and evaluates three models: **Linear Regression**, **Random Forest**, and an optional **LSTM**
- Downloads the **latest TCS stock data** live from Yahoo Finance via `yfinance`

---

## Dataset

**File:** `data/TCS_stock_history.csv`  
**Source:** Yahoo Finance (`TCS.NS`) via the `yfinance` Python library

| Column | Description |
|---|---|
| `Date` | Trading date (YYYY-MM-DD) |
| `Open` | Opening price (INR) on that day |
| `High` | Highest price reached during the day (INR) |
| `Low` | Lowest price reached during the day (INR) |
| `Close` | Closing (last) price of the day (INR) — **this is our prediction target** |
| `Volume` | Total number of shares traded on that day |
| `Dividends` | Dividend amount paid (0 on non-dividend days) |
| `Stock Splits` | Stock split ratio (0 on non-split days) |

---

## Project Structure

```
tcs-stock-data-live-latest/
│
├── data/
│   ├── TCS_stock_history.csv        # Historical data — place your CSV here
│   └── tcs_stock_latest.csv         # Auto-generated by download script
│
├── notebooks/
│   ├── 01_eda_tcs_stock.ipynb       # Full EDA with visualisations
│   └── 02_ml_model_tcs_stock.ipynb  # ML model training and evaluation
│
├── src/
│   ├── __init__.py                  # Makes src a Python package
│   ├── data_loader.py               # Load and clean the CSV dataset
│   ├── eda.py                       # All EDA visualisation functions
│   ├── features.py                  # Feature engineering pipeline
│   ├── models.py                    # LR, Random Forest, LSTM models
│   └── download_latest_tcs_data.py  # Download live data from Yahoo Finance
│
├── requirements.txt                 # All Python dependencies
├── README.md                        # This file
├── LICENSE                          # MIT open-source licence
└── .gitignore                       # Files excluded from Git
```

---

## High-Level Flow

1. **Data Ingestion**
	- `src/data_loader.py` prefers `data/tcs_stock_latest.csv`.
	- If missing, it auto-calls the online downloader and creates the CSV.
2. **EDA**
	- `notebooks/01_eda_tcs_stock.ipynb` explores trends, volume, correlation, and moving averages.
3. **Feature Engineering**
	- `src/features.py` adds lag, date, rolling-average, and volatility features.
4. **Modeling**
	- `notebooks/02_ml_model_tcs_stock.ipynb` runs Linear Regression, Random Forest, and optional LSTM.

This makes the project easy to understand for internship showcase and easy to extend for future experiments.

---

## Quickstart — Setup Instructions

### Prerequisites
- Python 3.8 or higher
- pip and optionally virtualenv

### Step 1: Clone the repository

```bash
git clone https://github.com/<your-username>/tcs-stock-data-live-latest.git
cd tcs-stock-data-live-latest
```

### Step 2: Create and activate a virtual environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install dependencies

```bash
pip install -r requirements.txt
```

> **Note:** TensorFlow (for the LSTM model) is included. If you don't need LSTM,
> remove the `tensorflow` line from `requirements.txt` to speed up installation.

### Step 4: Download the latest TCS data

```bash
python src/download_latest_tcs_data.py
```

This saves `data/tcs_stock_latest.csv`.

> You can also skip this step.
> If no CSV is found, `load_tcs_data()` will auto-download online data.

### Step 5: Launch Jupyter Notebook

```bash
jupyter notebook
```

Open `notebooks/01_eda_tcs_stock.ipynb` for EDA, then `notebooks/02_ml_model_tcs_stock.ipynb` for models.

---

## One-Click Colab (Single File)

Use this notebook if you want the full project flow in one place on any device:

- `notebooks/03_tcs_stock_one_click_colab.ipynb`

Direct link:

`https://colab.research.google.com/github/ManishPatil2005/tcs-stock-data-live-latest/blob/main/notebooks/03_tcs_stock_one_click_colab.ipynb`

It automatically:
- clones the repo,
- installs requirements,
- downloads latest TCS data,
- runs EDA,
- runs baseline ML models.

---

## Run in GitHub Codespaces / Dev Containers

This repo includes `.devcontainer/devcontainer.json` so contributors can run it without manual system setup.

### GitHub Codespaces

1. Open the repository on GitHub.
2. Click **Code** → **Codespaces** → **Create codespace on main**.
3. Wait for environment build (dependencies install automatically from `requirements.txt`).
4. Run:

```bash
python src/download_latest_tcs_data.py
jupyter notebook
```

### VS Code Dev Containers (local Docker)

1. Install Docker Desktop + VS Code extension **Dev Containers**.
2. Open repo in VS Code.
3. Run command: **Dev Containers: Reopen in Container**.
4. Environment starts with Python + required packages.

This gives reproducible behavior across local machines and cloud workspaces.

---

## Methodology

### 1. Exploratory Data Analysis (EDA)
- **Time-series plots** of Close price to visualise long-term trends
- **Volume analysis** to detect high-activity trading days
- **Correlation heatmap** to understand relationships between price columns
- **Moving averages** (5-day short, 30-day long) to smooth noise and detect trend direction
- **Buy/Sell signal crossover** — classic technical analysis indicator

### 2. Feature Engineering
The raw OHLCV data is extended with:
- **Calendar features:** Year, Month, Day, Day_of_Week
- **Lag features:** Prev_Close_1, Prev_Close_3, Prev_Close_7 (yesterday's price, 3 days ago, 7 days ago)
- **Rolling averages:** MA_7, MA_30 (short and medium trend)
- **Volatility:** STD_7, STD_30 (rolling standard deviation)
- **Derived:** Daily_Return (% change), Price_Range (High - Low)

### 3. Machine Learning Models

#### A. Linear Regression (Baseline)
A simple linear model that fits a weighted sum of input features to predict Close price.
Fast, interpretable, and useful as a performance benchmark.

#### B. Random Forest Regressor
An ensemble of 100 decision trees. Handles non-linear relationships and is resistant
to outliers. Feature importance scores reveal which inputs matter most.

#### C. LSTM (Optional)
A two-layer Long Short-Term Memory neural network that takes a rolling 60-day window
of Close prices as input and predicts the next day's price. Best suited for capturing
temporal dependencies in time series.

---

## How to Interpret Results

| Metric | Meaning | Good value |
|---|---|---|
| **MAE** | Average absolute error in INR | Lower is better |
| **RMSE** | Root mean squared error (penalises large errors more) | Lower is better |
| **R²** | Proportion of variance explained (0 to 1) | Closer to 1 is better |

> ⚠️ **Important:** High R² scores in stock prediction can indicate **look-ahead bias**
> (data leakage). Always use chronological train/test splits — never random shuffle.
> The models here use an 80/20 chronological split.

---

## Future Work

| Idea | Benefit |
|---|---|
| XGBoost / LightGBM | Often outperforms Random Forest on tabular data |
| ARIMA / SARIMA | Classical statistical time-series model |
| Hyperparameter tuning with Optuna or GridSearchCV | Improve model accuracy |
| Sentiment Analysis of news headlines | Add non-price signals |
| Streamlit / Flask web app deployment | Interactive real-time predictions |
| Walk-forward validation | More realistic evaluation avoiding leakage |

---

## Git & GitHub — Quick Reference

### Initialize and push to GitHub

```bash
# Navigate to the project folder
cd tcs-stock-data-live-latest

# 1. Initialize a local git repository
git init

# 2. Stage all files for the first commit
git add .

# 3. Create the first commit
git commit -m "Initial commit: TCS stock data analysis project"

# 4. Rename the default branch to 'main'
git branch -M main

# 5. Link your local repo to the GitHub remote
#    (Replace <your-username> and <repo-name> with your actual values)
git remote add origin https://github.com/<your-username>/tcs-stock-data-live-latest.git

# 6. Push to GitHub
git push -u origin main
```

### Subsequent updates

```bash
git add .
git commit -m "Add: description of what changed"
git push
```

### Useful Git commands

| Command | Purpose |
|---|---|
| `git status` | See which files are staged/unstaged |
| `git log --oneline` | View compact commit history |
| `git diff` | See changes not yet staged |
| `git branch` | List branches |
| `git checkout -b feature/new-model` | Create and switch to a new branch |

---

## License

This project is licensed under the **MIT License** — see [LICENSE](LICENSE) for details.

---

## Author

**Data Analyst Intern**  
Project: TCS Stock Data – Live and Latest  
Tools: Python, Pandas, NumPy, Matplotlib, Seaborn, scikit-learn, TensorFlow, yfinance  
Platform: VS Code + Jupyter Notebook
